# coding=utf-8
#
# BERT multi-class classification model
#
# Training data: data_LossDescription (or some other text field)
# Label class: A label for the corresponding input string (a coverageType, etc.)
#
# Some notes:
# - Training data is generated by the prepare_closed/open_training_data.ipynb notebooks.
# - For now, you need to hardcode the data directory (data_dir) into this script (see below).
#
# This script is based on code taken from the huggingface text-classification example (original licence below)
#
# https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py
#
# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import os
import sys
import json
import joblib
import torch
import pandas as pd
import numpy as np
from typing import Optional
from datasets import load_dataset
from dataclasses import dataclass, field
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    r2_score,
    classification_report,
)
from transformers import (
    AutoConfig,
    AutoModelForSequenceClassification,
    AutoTokenizer,
    EvalPrediction,
)
from transformers import GlueDataTrainingArguments as DataTrainingArguments
from transformers import (
    HfArgumentParser,
    Trainer,
    TrainingArguments,
    set_seed,
)


@dataclass
class ModelArguments:
    """
    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.
    """

    model_name_or_path: str = field(
        metadata={"help": "Path to pretrained model or model identifier from huggingface.co/models"}
    )
    config_name: Optional[str] = field(
        default=None, metadata={"help": "Pretrained config name or path if not the same as model_name"},
    )
    tokenizer_name: Optional[str] = field(
        default=None, metadata={"help": "Pretrained tokenizer name or path if not the same as model_name"},
    )
    cache_dir: Optional[str] = field(
        default=None, metadata={"help": "Where do you want to store the pretrained models downloaded from s3"},
    )


parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))

model_args, data_args, training_args = parser.parse_args_into_dataclasses()
# for now, the directory contraining the train/eval data is set here
# data_dir = "data/lob_bert_10_18_drop-gsmissing_vocabmap"
data_dir = data_args.data_dir
# the following line loads a joblib object (partial function) for
# performing the inverse of the target transformation - the data
# loaded in by this script is already target transformed.
print(data_dir)
logger = logging.getLogger(__name__)

# load id_to_label and label_to_id maps
with open(f"{data_dir}/id_to_label.json", "r") as f:
    id_to_label = json.load(f)

with open(f"{data_dir}/label_to_id.json", "r") as f:
    label_to_id = json.load(f)

N_LABELS = len(label_to_id)


def main():

    # if len(sys.argv) == 2 and sys.argv[1].endswith(".json"):
    #     # If we pass only one argument to the script and it's the path to a json file,
    #     # let's parse it to get our arguments.
    #     model_args, data_args, training_args = parser.parse_json_file(
    #         json_file=os.path.abspath(sys.argv[1])
    #     )
    # else:
    #     model_args, data_args, training_args = parser.parse_args_into_dataclasses()

    if (
        os.path.exists(training_args.output_dir)
        and os.listdir(training_args.output_dir)
        and training_args.do_train
        and not training_args.overwrite_output_dir
    ):
        raise ValueError(
            f"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome."
        )

    # Setup logging
    logging.basicConfig(
        format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
        datefmt="%m/%d/%Y %H:%M:%S",
        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,
    )
    logger.warning(
        "Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s",
        training_args.local_rank,
        training_args.device,
        training_args.n_gpu,
        bool(training_args.local_rank != -1),
        training_args.fp16,
    )
    logger.info("Training/evaluation parameters %s", training_args)

    # Set seed
    set_seed(training_args.seed)
    # Set number of labels to '1' for regression
    num_labels = N_LABELS
    # enable GPU
    # torch.set_default_tensor_type("torch.cuda.FloatTensor")

    # load config, tokenizer and the model
    config = AutoConfig.from_pretrained(
        model_args.config_name if model_args.config_name else model_args.model_name_or_path,
        num_labels=num_labels,
        cache_dir=model_args.cache_dir,
        label2id=label_to_id,
    )
    print(config)
    exit()
    tokenizer = AutoTokenizer.from_pretrained(
        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,
        cache_dir=model_args.cache_dir,
    )
    model = AutoModelForSequenceClassification.from_pretrained(
        model_args.model_name_or_path,
        from_tf=bool(".ckpt" in model_args.model_name_or_path),
        config=config,
        cache_dir=model_args.cache_dir,
    )

    #     # Get all of the model's parameters as a list of tuples.
    params = list(model.named_parameters())
    print("\n\nThe BERT model has {:} different named parameters.\n".format(len(params)))
    print("==== Embedding Layer ====\n")
    for p in params[0:5]:
        print("{:<55} {:>12}".format(p[0], str(tuple(p[1].size()))))
    print("\n==== First Transformer ====\n")
    for p in params[5:21]:
        print("{:<55} {:>12}".format(p[0], str(tuple(p[1].size()))))
    print("\n==== Output Layer ====\n")
    for p in params[-4:]:
        print("{:<55} {:>12}".format(p[0], str(tuple(p[1].size()))))
    print("\n\n")

    # load and prepare train and eval datasets
    train_dataset = load_dataset("csv", data_files=f"{data_dir}/train.csv")
    train_dataset = train_dataset.map(
        lambda e: tokenizer(e["data_CoverageType"], padding=True, truncation=True, max_length=64,), batched=True,
    )
    train_dataset.rename_column_("input_ids", "CoverageType_input_ids")
    train_dataset.rename_column_("attention_mask", "CoverageType_attention_mask")
    train_dataset.rename_column_("token_type_ids", "CoverageType_token_type_ids")
    print(train_dataset)
    train_dataset = train_dataset.map(
        lambda e: tokenizer(e["data_LossType"], padding=True, truncation=True, max_length=64,), batched=True,
    )
    train_dataset.rename_column_("input_ids", "LossType_input_ids")
    train_dataset.rename_column_("attention_mask", "LossType_attention_mask")
    train_dataset.rename_column_("token_type_ids", "LossType_token_type_ids")

    train_dataset = train_dataset.map(
        lambda e: tokenizer(e["data_LossDescription"], padding=True, truncation=True, max_length=128,), batched=True,
    )
    train_dataset.rename_column_("input_ids", "LossDesc_input_ids")
    train_dataset.rename_column_("attention_mask", "LossDesc_attention_mask")
    train_dataset.rename_column_("token_type_ids", "LossDesc_token_type_ids")
    
    train_dataset.set_format(
        type="torch",
        columns=[
            "CoverageType_input_ids",
            "CoverageType_attention_mask",
            "CoverageType_token_type_ids",
            "LossType_input_ids",
            "LossType_attention_mask",
            "LossType_token_type_ids",
            "LossDesc_input_ids",
            "LossDesc_attention_mask",
            "LossDesc_token_type_ids",
            "labels",
        ],
    )

    eval_dataset = load_dataset("csv", data_files=f"{data_dir}/valid.csv")
    eval_dataset = eval_dataset.map(
        lambda e: tokenizer(e["data_CoverageType"], padding=True, truncation=True, max_length=256,), batched=True,
    )
    eval_dataset.rename_column_("input_ids", "CoverageType_input_ids")
    eval_dataset.rename_column_("attention_mask", "CoverageType_attention_mask")
    eval_dataset.rename_column_("token_type_ids", "CoverageType_token_type_ids")

    eval_dataset = eval_dataset.map(
        lambda e: tokenizer(e["data_LossType"], padding=True, truncation=True, max_length=256,), batched=True,
    )
    eval_dataset.rename_column_("input_ids", "LossType_input_ids")
    eval_dataset.rename_column_("attention_mask", "LossType_attention_mask")
    eval_dataset.rename_column_("token_type_ids", "LossType_token_type_ids")

    eval_dataset = eval_dataset.map(
        lambda e: tokenizer(e["data_LossDescription"], padding=True, truncation=True, max_length=256,), batched=True,
    )
    eval_dataset.rename_column_("input_ids", "LossDesc_input_ids")
    eval_dataset.rename_column_("attention_mask", "LossDesc_attention_mask")
    eval_dataset.rename_column_("token_type_ids", "LossDesc_token_type_ids")

    eval_dataset.set_format(
        type="torch",
        columns=[
            "CoverageType_input_ids",
            "CoverageType_attention_mask",
            "CoverageType_token_type_ids",
            "LossType_input_ids",
            "LossType_attention_mask",
            "LossType_token_type_ids",
            "LossDesc_input_ids",
            "LossDesc_attention_mask",
            "LossDesc_token_type_ids",
            "labels",
        ],
    )

    print("post dataset build")
    # custom metrics function to be passed to the Trainer
    def reg_metrics(p: EvalPrediction):
        y_pred = np.squeeze(p.predictions)
        y_true = np.squeeze(p.label_ids)

        y_pred = [sample.index(max(sample)) for sample in y_pred.tolist()]
        y_pred = [id_to_label[str(x)] for x in y_pred]

        y_true = [id_to_label[str(x)] for x in y_true]

        cr = classification_report(y_true, y_pred, output_dict=True)
        print("\nValidation set classification report:\n")
        print(pd.DataFrame(cr).T)
        print("\n")
        metrics = cr
        return metrics

    # Initialize our Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset.get("train"),
        eval_dataset=eval_dataset.get("train"),  # this is supposed to be 'train' - for now
        #         tokenizer=tokenizer,
        compute_metrics=reg_metrics,
    )

    # Training
    if training_args.do_train:
        trainer.train(
            model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None
        )
        trainer.save_model()
        # For convenience, we also re-save the tokenizer to the same directory,
        # if trainer.is_world_master():
        tokenizer.save_pretrained(training_args.output_dir)

    # Evaluation
    eval_results = {}
    if training_args.do_eval:
        logger.info("*** Evaluate ***")
        eval_datasets = [eval_dataset]
        for eval_dataset in eval_datasets:
            eval_results = trainer.predict(test_dataset=eval_dataset.get("train"))
            pred_df = pd.DataFrame(
                {
                    "predictions": np.squeeze(eval_results.predictions).tolist(),
                    "y_true": np.squeeze(eval_results.label_ids).tolist(),
                }
            )
            metrics_df = pd.DataFrame([eval_results.metrics])
            print(metrics_df)
            pred_df.to_csv(f"{training_args.output_dir}/eval_predictions.csv", index=False)
            metrics_df.to_csv(f"{training_args.output_dir}/eval_metrics.csv", index=False)


def _mp_fn(index):
    main()


if __name__ == "__main__":
    main()
